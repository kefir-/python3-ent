{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ent implemented in python\n",
    "\n",
    "This notebook shows how to implement the functionality from the `ent` tool in python. Please note that this is only written to replicate the calculations. The `ent` tool will handle huge files well, but this script won't.\n",
    "\n",
    "The code on this page is released into the public domain, just like the `ent` tool. Copying the license from [the `ent` website](http://www.fourmilab.ch/random/):\n",
    "\n",
    "```\n",
    "This software is in the public domain. Permission to use, copy, modify, and distribute this software and its documentation for any purpose and without fee is hereby granted, without any conditions or restrictions. This software is provided “as is” without express or implied warranty. \n",
    "```\n",
    "\n",
    "## Input and expected output\n",
    "\n",
    "Let's start by creating a file containing random data called `random.dat`:\n",
    "```bash\n",
    "dd if=/dev/urandom of=random.dat bs=8k count=1\n",
    "```\n",
    "You can also test with a file with only zeros called `zeros.dat`\n",
    "```bash\n",
    "dd if=/dev/zero of=zeros.dat bs=8k count=1\n",
    "```\n",
    "And a file with incrementing numbers called `inc8kb.dat`:\n",
    "```bash\n",
    "seq 0 255 | while read l; do h=$(printf \"\\\\\\x%02x\" $l); echo -ne \"$h\"; done > inc.dat\n",
    "seq 16 | while read l; do cat inc.dat; done >> inc8kb.dat\n",
    "```\n",
    "\n",
    "Next we analyze this file with the tool `ent`, and inspect the output for later comparison. For my file, it looked like this:\n",
    "\n",
    "```bash\n",
    "$ ent random.dat \n",
    "Entropy = 7.979943 bits per byte.\n",
    "\n",
    "Optimum compression would reduce the size\n",
    "of this 8192 byte file by 0 percent.\n",
    "\n",
    "Chi square distribution for 8192 samples is 226.62, and randomly\n",
    "would exceed this value 89.91 percent of the times.\n",
    "\n",
    "Arithmetic mean value of data bytes is 127.7104 (127.5 = random).\n",
    "Monte Carlo value for Pi is 3.079853480 (error 1.97 percent).\n",
    "Serial correlation coefficient is -0.016501 (totally uncorrelated = 0.0).\n",
    "```\n",
    "\n",
    "## Setup and code\n",
    "\n",
    "We want to recreate these in python3. Install numpy and scipy to continue:\n",
    "```\n",
    "apt install python3-numpy python3-scipy\n",
    "```\n",
    "\n",
    "First we'll read our data file, and convert the data to a numeric array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "f = open(\"random.dat\", \"rb\") # try also zeros.dat and inc8kb.dat\n",
    "data = f.read()\n",
    "data_num = [x for x in data]\n",
    "\n",
    "print(type(data))\n",
    "print(type(data_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, data is a byte string, while data_num is a list of integers. We need the list of integers to do further calculations. First, we'll calculate the basic entropy, which should match the basic entropy measure from `ent`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy = 8.000000 bits per byte.\n"
     ]
    }
   ],
   "source": [
    "h = np.histogram(data_num, bins=256)\n",
    "e = scipy.stats.entropy(h[0], base=2)\n",
    "# print(e)\n",
    "print(\"Entropy = {:.6f} bits per byte.\".format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll output the same value as `ent` for the optimum compression. This is simply calculated from the entropy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum compression would reduce the size\n",
      "of this 8192 byte file by 0 percent.\n"
     ]
    }
   ],
   "source": [
    "optimum_compression = (100 * (8 - e)) / 8\n",
    "# print(int(round(optimum_compression)))\n",
    "print(\"Optimum compression would reduce the size\")\n",
    "print(\"of this {} byte file by {:.0f} percent.\".format(len(data), round(optimum_compression)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step to replicate `ent`'s functionality is to calculate the chi square distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi square distribution for 8192 samples is 0.00, and randomly\n",
      "would exceed this value 100.00 percent of the time.\n"
     ]
    }
   ],
   "source": [
    "chi = scipy.stats.chisquare(h[0])\n",
    "# print(chi)\n",
    "print(\"Chi square distribution for {} samples is {:.2f}, and randomly\".format(len(data), chi.statistic))\n",
    "print(\"would exceed this value {:.2f} percent of the time.\".format(chi.pvalue*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next output is the arithmetic mean, which is just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arithmetic mean value of data bytes is 127.5000 (127.5 = random).\n"
     ]
    }
   ],
   "source": [
    "totalc = len(data_num)\n",
    "datasum = np.sum(data_num)\n",
    "\n",
    "print(\"Arithmetic mean value of data bytes is {:.4f} ({:.1f} = random).\".format(datasum/totalc, 127.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Monte Carlo value for pi requires a bit more manual calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monte Carlo value for Pi is 2.842490842 (error 9.52 percent).\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "bytes_per_coord = 6 # randtest.c's MONTEN value\n",
    "incirc = math.pow(math.pow(256, bytes_per_coord / 2) - 1, 2.0)\n",
    "inmont = 0\n",
    "mcount = 0\n",
    "for i in range(0, len(data_num) - (bytes_per_coord - 1), bytes_per_coord):\n",
    "    mcount = mcount + 1\n",
    "    # use 3 bytes for the x coordinate, and the next 3 bytes for the y coordinate\n",
    "    x_coord = data_num[i+0]*256*256 + data_num[i+1]*256 + data_num[i+2]\n",
    "    y_coord = data_num[i+3]*256*256 + data_num[i+4]*256 + data_num[i+5]\n",
    "    if (x_coord * x_coord + y_coord * y_coord <= incirc):\n",
    "        inmont = inmont + 1\n",
    "montepi = (4.0 * inmont / mcount)\n",
    "print(\"Monte Carlo value for Pi is {:.9f} (error {:.2f} percent).\".format(montepi, 100*abs(math.pi-montepi)/math.pi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, `ent` outputs the serial correlation value. We have to calculate this ourselves as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial correlation coefficient is 0.976654 (totally uncorrelated = 0.0)\n"
     ]
    }
   ],
   "source": [
    "scct1 = scct2 = scct3 = 0.0\n",
    "scclast = None\n",
    "for sccun in data_num:\n",
    "    if scclast is None:\n",
    "        scclast = 0\n",
    "        sccu0 = sccun\n",
    "    else:\n",
    "        scct1 = scct1 + (scclast * sccun)\n",
    "    scct2 = scct2 + sccun\n",
    "    scct3 = scct3 + (sccun * sccun)\n",
    "    scclast = sccun\n",
    "\n",
    "scct1 = scct1 + (scclast * sccu0)\n",
    "scct2 = scct2 * scct2\n",
    "scc = (totalc * scct3) - scct2\n",
    "if scc == 0.0:\n",
    "    scc = -100000\n",
    "else:\n",
    "    scc = (totalc * scct1 - scct2) / scc\n",
    "\n",
    "if scc >= -99999:\n",
    "    print(\"Serial correlation coefficient is {:.6f} (totally uncorrelated = 0.0)\".format(scc))\n",
    "else:\n",
    "    print(\"Serial correlation coefficient is undefined (all values equal!).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
